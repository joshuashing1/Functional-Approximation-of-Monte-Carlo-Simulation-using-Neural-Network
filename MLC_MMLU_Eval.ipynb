{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNiFgWbcIrDZrRYQyEcSSvJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joshuashing1/MCNN_Simulation/blob/main/MLC_MMLU_Eval.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XoY0jbdP_BE3"
      },
      "outputs": [],
      "source": [
        "!pip install datasets\n",
        "!pip install langchain\n",
        "!pip install langchain_openai\n",
        "!pip install openai\n",
        "!pip install numpy\n",
        "!pip install --pre -U -f https://mlc.ai/wheels mlc-llm-nightly mlc-ai-nightly\n",
        "!pip install git-lfs"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import mlc_llm; print(mlc_llm)"
      ],
      "metadata": {
        "id": "FkMXvyzf_B1g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.prompts import HumanMessagePromptTemplate\n",
        "from mlc_llm import MLCEngine"
      ],
      "metadata": {
        "id": "U6sIPtX6_Gtt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# raw dataset\n",
        "mmlu_dataset = load_dataset(\n",
        "    path = 'cais/mmlu',\n",
        "    name = 'all',\n",
        "    trust_remote_code = True,\n",
        "    split = 'dev'\n",
        ")\n",
        "print(mmlu_dataset)\n",
        "\n",
        "# pandas version of dataset\n",
        "df_mmlu_full = mmlu_dataset.to_pandas()\n",
        "\n",
        "# select number of data\n",
        "df_mmlu = df_mmlu_full.head(2)\n",
        "print(df_mmlu['choices'])\n",
        "\n",
        "#choices = df_mmlu['choices'].apply(lambda x: ', '.join(x))\n",
        "#print(question)\n",
        "# print(df_mmlu['choices'].dtype)"
      ],
      "metadata": {
        "id": "I11GwVoq_JI9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Data Wrangling for True Values\n",
        "true_choices = []\n",
        "\n",
        "# Enter in true choices into list\n",
        "def true_value_conversion(x):\n",
        "    if x == 0:\n",
        "        return 'A'\n",
        "    elif x == 1:\n",
        "        return 'B'\n",
        "    elif x == 2:\n",
        "        return 'C'\n",
        "    else:\n",
        "        return 'D'\n",
        "\n",
        "for answer, row in df_mmlu.iterrows():\n",
        "    true_choices.append(true_value_conversion(row['answer']))\n",
        "    # true_choices.append(str(row['answer']))"
      ],
      "metadata": {
        "id": "rmXnBs_N_Lok"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Data Wrangling for LLM Values\n",
        "llm_choices = []\n",
        "\n",
        "df_mmlu['choices'] = df_mmlu['choices'].astype(str)\n",
        "print(df_mmlu['choices'])\n",
        "\n",
        "# Define the prefixes\n",
        "prefixes = ['A. ', 'B. ', 'C. ', 'D. ']\n",
        "\n",
        "# Define a function to add prefixes to the elements of the list\n",
        "def add_prefixes(lst, prefixes):\n",
        "    return [f\"{prefix}{item}\" for prefix, item in zip(prefixes, lst)]\n",
        "\n",
        "# Apply the function to the DataFrame column\n",
        "# df_mmlu['choices_with_prefix'] = add_prefixes(df_mmlu['choices'], prefixes)\n",
        "df_mmlu['choices_with_prefix'] = df_mmlu['choices'].apply(lambda x: add_prefixes(x, prefixes))\n",
        "\n",
        "print(df_mmlu['choices_with_prefix'])"
      ],
      "metadata": {
        "id": "otYi1e5g_OXF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Call on the engine API\n",
        "model = \"HF://mlc-ai/Phi-3-mini-128k-instruct-q4f16_2-MLC\"\n",
        "engine = MLCEngine(model)"
      ],
      "metadata": {
        "id": "aGH91rou_RNF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(df_mmlu)):\n",
        "    response = engine.chat.completions.create(\n",
        "        messages=[{\"role\": \"user\", \"content\": \"What is 1+1? Think step-by-step to select the best option. The options are A. 2, B. 3, C. 4, D. 5. A\"},\n",
        "        {\"role\": \"user\", \"content\": \"Which colour is primary colour? Think step-by-step to select the best option. The options are A. yellow, B. cyan, C. red, D. pink. C\"},\n",
        "        {\"role\": \"user\", \"content\": \"What is the capital city of China? Think step-by-step to select the best option. The options are A. Hong Kong, B. Beijing, C. Shanghai, D. Tianjin. B\"},\n",
        "        {\"role\": \"user\", \"content\": \"She is ___ home. Think step-by-step to select the best option. The options are A. at, B. in, C. on, D. from. A\"},\n",
        "        {\"role\": \"user\", \"content\": \"60 minutes is ___? Think step-by-step to select the best option. The options are A. one hour, B. half an hour, C. two hours, D. three hours. A\"},\n",
        "        {\"role\": \"user\", \"content\": f\"{df_mmlu.loc[i, \"question\"]}. Choose the best option without explaination. {df_mmlu.loc[i, \"choices\"]}.\"}],\n",
        "        model=model,\n",
        "        #stream=False,\n",
        "    )\n",
        "    llm_choices.append(response.choices[0].message.content[0])\n",
        "\n",
        "print(llm_choices)"
      ],
      "metadata": {
        "id": "DuDj7TB7_Vbs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluation on MMLU dataset\n",
        "# for i in range(len(true_choices)):\n",
        "for response in engine.chat.completions.create(\n",
        "    messages=[#{\"role\": \"user\", \"content\": \"What is 1+1? Think step-by-step to select the best option. The options are A. 2, B. 3, C. 4, D. 5. A\"},\n",
        "    #{\"role\": \"user\", \"content\": \"Which colour is primary colour? Think step-by-step to select the best option. The options are A. yellow, B. cyan, C. red, D. pink. C\"},\n",
        "    #{\"role\": \"user\", \"content\": \"What is the capital city of China? Think step-by-step to select the best option. The options are A. Hong Kong, B. Beijing, C. Shanghai, D. Tianjin. B\"},\n",
        "    #{\"role\": \"user\", \"content\": \"Which of the following is not a security exploit? Choose the best option without explaination. The options are A. Eavesdropping, B. Cross-site scripting, C. Authentication, D. SQL Injection.\",}\n",
        "    {\"role\": \"user\", \"content\": \"She is ___ home. Choose the best option without explaination. The options are A. at, B. in, C. on, D. from. A\"}],\n",
        "    model=model,\n",
        "    stream=True,\n",
        "):\n",
        "    for choice in response.choices:\n",
        "        print(choice.delta.content, end=\"\", flush=True)\n",
        "print(\"\\n\")\n",
        "\n",
        "# Get last letter of the \\n string\n",
        "llm_choices.append(\"\\n\")\n",
        "\n",
        "# terminate engine per iteration\n",
        "engine.terminate()"
      ],
      "metadata": {
        "id": "q2hDox7u_WGG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check accuracy\n",
        "correct_choices = []\n",
        "\n",
        "for i in range(len(true_choices)):\n",
        "    if llm_choices[i] == true_choices[i]:\n",
        "        correct_choices.append(1)\n",
        "    else:\n",
        "        correct_choices.append(0)\n",
        "\n",
        "llm_accuracy = np.mean(correct_choices)\n",
        "print(llm_accuracy)"
      ],
      "metadata": {
        "id": "URDHxoqW_Z_F"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}